{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b387c7-6ea3-4525-9cb6-cb1ea01ab5ee",
   "metadata": {},
   "source": [
    "# Notebook Overview: Tuning for HAN-GRU Model with Learning Rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9feff4-f29e-487b-8fc2-261b3ca10c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cbb16a-e378-4657-b5ae-31323e6ff7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/lyrics_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985528bb-381e-46e9-9957-687d68c0c1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218162/218162 [00:23<00:00, 9461.18it/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for line in tqdm(df['lyrics']):\n",
    "    counter.update(tokenizer(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ea5f2d-d0be-42d6-bbfa-8e6e03d674b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary using build_vocab_from_iterator\n",
    "vocab = build_vocab_from_iterator([tokenizer(line) for line in df['lyrics']],\n",
    "                                  specials=['<unk>', '<pad>'], min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b3d5e4-9981-406c-8732-c42c7989166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "indexed_data = [torch.tensor([vocab[token] for token in tokenizer(line)])\n",
    "                for line in df['lyrics']]\n",
    "\n",
    "# Include padding for same shape size\n",
    "max_seq_length = max(len(seq) for seq in indexed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e43bc86f-4b35-4c40-bb58-c245656d7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data = pad_sequence(indexed_data, batch_first=True, padding_value=vocab['<pad>'])\n",
    "indexed_labels = torch.tensor(label_encoder.fit_transform(df['genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7342cb7d-8be7-484f-abc6-661c54d9bc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174,529 training samples\n",
      "43,633 validation samples\n"
     ]
    }
   ],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics, genre):\n",
    "        self.lyrics = lyrics\n",
    "        self.genre = genre\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.genre)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.lyrics[idx], self.genre[idx]\n",
    "\n",
    "dataset = LyricsDataset(padded_data, indexed_labels)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0fd8314-1208-454a-bb6d-b1049e45bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b4c1d-eef3-4138-974e-ee31d4d4f30e",
   "metadata": {},
   "source": [
    "## HAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd239af6-7bd7-4c33-8608-153661174260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WordAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(WordAttention, self).__init__()\n",
    "        self.word_weights = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, rnn_output):\n",
    "        word_scores = self.word_weights(rnn_output).squeeze(-1)\n",
    "        word_scores = torch.softmax(word_scores, dim=-1)\n",
    "        weighted_rnn_output = rnn_output * word_scores.unsqueeze(-1)\n",
    "        sentence_embeddings = torch.sum(weighted_rnn_output, dim=1)\n",
    "        return sentence_embeddings, word_scores\n",
    "\n",
    "class SentenceAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SentenceAttention, self).__init__()\n",
    "        self.sentence_weights = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, rnn_output):\n",
    "        sentence_scores = self.sentence_weights(rnn_output).squeeze(-1)\n",
    "        sentence_scores = torch.softmax(sentence_scores, dim=-1)\n",
    "        weighted_rnn_output = rnn_output * sentence_scores.unsqueeze(-1)\n",
    "        document_embedding = torch.sum(weighted_rnn_output, dim=1)\n",
    "        return document_embedding, sentence_scores\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.word_rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.word_attention = WordAttention(hidden_size * 2)\n",
    "        self.sentence_rnn = nn.GRU(hidden_size * 2, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.sentence_attention = SentenceAttention(hidden_size * 2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        word_embedded = self.embedding(inputs)\n",
    "        word_output, _ = self.word_rnn(word_embedded)\n",
    "        sentence_embeddings, _ = self.word_attention(word_output)\n",
    "\n",
    "        sentence_output, _ = self.sentence_rnn(word_output)\n",
    "        document_embedding, _ = self.sentence_attention(sentence_output)\n",
    "\n",
    "        output = self.fc(document_embedding)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b56644b8-1442-4036-97d9-4b38bce2ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAN(\n",
      "  (embedding): Embedding(75199, 512)\n",
      "  (word_rnn): GRU(512, 128, batch_first=True, bidirectional=True)\n",
      "  (word_attention): WordAttention(\n",
      "    (word_weights): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (sentence_rnn): GRU(256, 128, batch_first=True, bidirectional=True)\n",
      "  (sentence_attention): SentenceAttention(\n",
      "    (sentence_weights): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 512 \n",
    "hidden_size = 128  \n",
    "output_size = len(df['genre'].unique())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize your HAN model, optimizer, and criterion\n",
    "model = HAN(vocab_size, embedding_dim, hidden_size, output_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14658154-c6ef-4d11-a38f-f4de1f6105c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [04:17<17:08, 257.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.4360, Accuracy: 54.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [08:34<12:51, 257.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 1.1690, Accuracy: 62.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [12:51<08:34, 257.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.8187, Accuracy: 73.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [17:09<04:17, 257.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.4058, Accuracy: 87.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [21:28<00:00, 257.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.1618, Accuracy: 95.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "        num_correct += (predicted == labels).sum().item()  # Accumulate correct predictions\n",
    "        total += labels.size(0) \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss per epoch\n",
    "    accuracy = 100 * num_correct / total  # Calculate accuracy for the epoch\n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_train_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ae76eaa-c603-4c36-b62f-b881ca36c068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4080, Accuracy: 51.22%\n"
     ]
    }
   ],
   "source": [
    "# Validation loop (optional)\n",
    "model.eval()\n",
    "val_running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        val_loss = criterion(outputs, labels)\n",
    "        val_running_loss += val_loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    avg_val_loss = val_running_loss / len(validation_dataloader)\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456a999-3e20-4cc1-83e3-40139270c32d",
   "metadata": {},
   "source": [
    "## HAN-GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3969351-63bc-471f-bdeb-03923246c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AttLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(AttLayer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = nn.Parameter(torch.randn(input_size, hidden_dim))\n",
    "        self.bw = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.uw = nn.Parameter(torch.randn(hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_words, hidden_size = x.size()\n",
    "        x_reshaped = x.reshape(-1, hidden_size)\n",
    "\n",
    "        ui = torch.tanh(torch.matmul(x_reshaped, self.W) + self.bw)\n",
    "        intermed = torch.sum(self.uw * ui, dim=1)\n",
    "\n",
    "        intermed = intermed.view(batch_size, num_words)\n",
    "        weights = torch.softmax(intermed, dim=-1)\n",
    "        weights = weights.unsqueeze(-1)\n",
    "\n",
    "        weighted_input = x * weights\n",
    "        return torch.sum(weighted_input, dim=1)\n",
    "\n",
    "class HAN_GRU(nn.Module):\n",
    "    def __init__(self, num_words, embedding_vector_length, hidden_size, attention_size, max_words_per_line, max_num_lines, output_size):\n",
    "        super(HAN_GRU, self).__init__()\n",
    "\n",
    "        self.word_embedding = nn.Embedding(num_words, embedding_vector_length)\n",
    "        self.word_gru = nn.GRU(embedding_vector_length, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.word_attention = AttLayer(hidden_size * 2, attention_size)\n",
    "\n",
    "        self.sentence_gru = nn.GRU(hidden_size * 2, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.sentence_attention = AttLayer(hidden_size * 2, attention_size)\n",
    "\n",
    "        self.max_words_per_line = max_words_per_line\n",
    "        self.max_num_lines = max_num_lines\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        word_embedded = self.word_embedding(inputs)\n",
    "\n",
    "        # Word-level GRU\n",
    "        word_output, _ = self.word_gru(word_embedded)\n",
    "        word_attention_output = self.word_attention(word_output)\n",
    "\n",
    "        # Reshape for sentence-level GRU\n",
    "        batch_size = word_attention_output.size(0)\n",
    "        sentence_input = word_attention_output.view(batch_size, -1, word_attention_output.size(-1))\n",
    "\n",
    "        sentence_output, _ = self.sentence_gru(sentence_input)\n",
    "        sentence_attention_output = self.sentence_attention(sentence_output)\n",
    "\n",
    "        # Reshape for document-level output\n",
    "        document_output = sentence_attention_output.view(batch_size, -1)\n",
    "        output = self.fc(self.dropout(document_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f25c46-910b-4467-9eca-87a681241c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Words Per Line: 6232\n",
      "Max Number of Lines: 759\n"
     ]
    }
   ],
   "source": [
    "# Calculate max words per line and max number of lines\n",
    "max_words_per_line = df['lyrics'].apply(lambda x: len(x.split())).max()\n",
    "max_num_lines = df['lyrics'].apply(lambda x: len(x.split('\\n'))).max()\n",
    "print(f\"Max Words Per Line: {max_words_per_line}\")\n",
    "print(f\"Max Number of Lines: {max_num_lines}\")\n",
    "\n",
    "attention_size = 100\n",
    "hidden_size = 128\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 512 \n",
    "output_size = len(df['genre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d31361b-f230-4150-8d5a-d1bf5490ebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAN_GRU(\n",
      "  (word_embedding): Embedding(245576, 512)\n",
      "  (word_gru): GRU(512, 128, batch_first=True, bidirectional=True)\n",
      "  (word_attention): AttLayer()\n",
      "  (sentence_gru): GRU(256, 128, batch_first=True, bidirectional=True)\n",
      "  (sentence_attention): AttLayer()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your model, optimizer, criterion, and data loaders defined\n",
    "\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize your HAN-GRU model, optimizer, and criterion\n",
    "model = HAN_GRU(vocab_size, embedding_dim, hidden_size, attention_size,\n",
    "                max_words_per_line, max_num_lines, output_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b655dd2-db73-47e6-acfa-29cb2d1de0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:52<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 1.5594 Train Accuracy: 51.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:47<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Train Loss: 1.4717 Train Accuracy: 53.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:48<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Train Loss: 1.4163 Train Accuracy: 55.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:48<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Train Loss: 1.3781 Train Accuracy: 56.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:48<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Train Loss: 1.3427 Train Accuracy: 57.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:48<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Train Loss: 1.3057 Train Accuracy: 58.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:47<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Train Loss: 1.2691 Train Accuracy: 59.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:46<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Train Loss: 1.2147 Train Accuracy: 61.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:45<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Train Loss: 1.1511 Train Accuracy: 63.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5455/5455 [10:45<00:00,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] Train Loss: 1.0869 Train Accuracy: 65.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    epoch_accuracy = (correct_predictions / total_predictions) * 100\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_accuracy)\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {epoch_loss:.4f} Train Accuracy: {epoch_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44012a8d-57f5-4e44-ae66-070db72a3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.2912, Accuracy: 59.64%\n"
     ]
    }
   ],
   "source": [
    "# Validation loop (optional)\n",
    "model.eval()\n",
    "val_running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        val_loss = criterion(outputs, labels)\n",
    "        val_running_loss += val_loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    avg_val_loss = val_running_loss / len(validation_dataloader)\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27b07b-9a7c-4f60-84c7-3d4205b9ef58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
