{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b387c7-6ea3-4525-9cb6-cb1ea01ab5ee",
   "metadata": {},
   "source": [
    "# Notebook Overview: Training Gated Recurrent Unit (GRU) Models\n",
    "\n",
    "This notebook documents the training process of two models utilizing the Gated Recurrent Unit (GRU) architecture. Due to extended training durations, the initial 25,000 rows/lyrics from the dataset were employed.\n",
    "\n",
    "The models under development are as follows:\n",
    "- Bidirectional GRU Network\n",
    "- Bidirectional GRU Network with a Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9feff4-f29e-487b-8fc2-261b3ca10c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50cbb16a-e378-4657-b5ae-31323e6ff7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/lyrics_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc14baa-6437-43df-a947-fc90377561a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "985528bb-381e-46e9-9957-687d68c0c1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:02<00:00, 9362.72it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for line in tqdm(df['lyrics']):\n",
    "    counter.update(tokenizer(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ea5f2d-d0be-42d6-bbfa-8e6e03d674b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary using build_vocab_from_iterator\n",
    "vocab = build_vocab_from_iterator([tokenizer(line) for line in df['lyrics'][:25000]],\n",
    "                                  specials=['<unk>', '<pad>'], min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b3d5e4-9981-406c-8732-c42c7989166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "indexed_data = [torch.tensor([vocab[token] for token in tokenizer(line)])\n",
    "                for line in df['lyrics'][:25000]]\n",
    "\n",
    "# Include padding for same shape size\n",
    "max_seq_length = max(len(seq) for seq in indexed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e43bc86f-4b35-4c40-bb58-c245656d7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data = pad_sequence(indexed_data, batch_first=True, padding_value=vocab['<pad>'])\n",
    "indexed_labels = torch.tensor(label_encoder.fit_transform(df['genre'][:25000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7342cb7d-8be7-484f-abc6-661c54d9bc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20,000 training samples\n",
      "5,000 validation samples\n"
     ]
    }
   ],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics, genre):\n",
    "        self.lyrics = lyrics\n",
    "        self.genre = genre\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.genre)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.lyrics[idx], self.genre[idx]\n",
    "\n",
    "dataset = LyricsDataset(padded_data, indexed_labels)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0fd8314-1208-454a-bb6d-b1049e45bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=24\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f85725-f1b2-4d3f-957b-2744f20c2f0a",
   "metadata": {},
   "source": [
    "## Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd239af6-7bd7-4c33-8608-153661174260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_size)  # Output size doubled due to bidirectionality\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        gru_out, _ = self.gru(embedded)\n",
    "        # Concatenate the last hidden state from both directions\n",
    "        combined = torch.cat((gru_out[:, -1, :hidden_dim], gru_out[:, 0, hidden_dim:]), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b56644b8-1442-4036-97d9-4b38bce2ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BidirectionalGRU(\n",
      "  (embedding): Embedding(72516, 512)\n",
      "  (gru): GRU(512, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=11, bias=True)\n",
      ")\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 512 \n",
    "hidden_dim = 128  \n",
    "output_size = len(df['genre'].unique())\n",
    "\n",
    "# Initialize the model\n",
    "model = BidirectionalGRU(vocab_size, embedding_dim, hidden_dim, output_size)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5  # Number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device) \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14658154-c6ef-4d11-a38f-f4de1f6105c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:32<02:11, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.6804, Accuracy: 46.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:05<01:37, 32.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 1.4542, Accuracy: 53.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:37<01:05, 32.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 1.2246, Accuracy: 60.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:10<00:32, 32.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.9845, Accuracy: 68.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:42<00:00, 32.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.7146, Accuracy: 77.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "        num_correct += (predicted == labels).sum().item()  # Accumulate correct predictions\n",
    "        total += labels.size(0) \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss per epoch\n",
    "    accuracy = 100 * num_correct / total  # Calculate accuracy for the epoch\n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_train_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ae76eaa-c603-4c36-b62f-b881ca36c068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.7380, Accuracy: 50.40%\n"
     ]
    }
   ],
   "source": [
    "# Validation loop (optional)\n",
    "model.eval()\n",
    "val_running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        val_loss = criterion(outputs, labels)\n",
    "        val_running_loss += val_loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    avg_val_loss = val_running_loss / len(validation_dataloader)\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb136d-f420-456a-bcb7-6fe9b1f6e942",
   "metadata": {},
   "source": [
    "## Bidirectional GRU with Dropout Layer\n",
    "\n",
    "Observing indications of overfitting in our previous bidirectional GRU architecture, evident through rapid loss reduction and notably high accuracy, we've introduced a dropout layer as a strategy to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8200d73b-2cf3-4672-b3f7-b2a45fbb22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, dropout=0.2):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.dropout(embedded)\n",
    "        gru_out, _ = self.gru(embedded)\n",
    "        combined = torch.cat((gru_out[:, -1, :hidden_dim], gru_out[:, 0, hidden_dim:]), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99477a84-7d8b-4595-aedc-1da327ea9fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BidirectionalGRU(\n",
      "  (embedding): Embedding(72516, 512)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (gru): GRU(512, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=11, bias=True)\n",
      ")\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 512 \n",
    "hidden_dim = 128  \n",
    "output_size = len(df['genre'].unique())\n",
    "\n",
    "# Initialize the model\n",
    "model = BidirectionalGRU(vocab_size, embedding_dim, hidden_dim, output_size)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5  # Number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device) \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f56937bd-9777-4612-af53-866864f00df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:32<02:10, 32.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.6884, Accuracy: 46.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:04<01:37, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 1.4560, Accuracy: 53.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:37<01:04, 32.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 1.2582, Accuracy: 59.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:09<00:32, 32.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 1.0623, Accuracy: 66.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:42<00:00, 32.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.8841, Accuracy: 71.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "        num_correct += (predicted == labels).sum().item()  # Accumulate correct predictions\n",
    "        total += labels.size(0) \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss per epoch\n",
    "    accuracy = 100 * num_correct / total  # Calculate accuracy for the epoch\n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_train_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbf91cab-a6b5-4852-98ba-a03673b8d007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.5735, Accuracy: 54.66%\n"
     ]
    }
   ],
   "source": [
    "# Validation loop (optional)\n",
    "model.eval()\n",
    "val_running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        val_loss = criterion(outputs, labels)\n",
    "        val_running_loss += val_loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    avg_val_loss = val_running_loss / len(validation_dataloader)\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff09e65-087d-490b-abb0-0432203196d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
